{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Example LSTM model for Mark Watson's book \"Practical Artificial Intelligence Programming in Python\"**\n",
        "\n",
        "https://leanpub.com/python-ai"
      ],
      "metadata": {
        "id": "mgMVi3T11g0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "print('\\n'.join(gpu_info))"
      ],
      "metadata": {
        "id": "XmI1RD-N1rm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the data for S3:**"
      ],
      "metadata": {
        "id": "smswg4GX2jAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = get_file('nietzsche.txt', origin=\n",
        "    'https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print('corpus length:', len(text))"
      ],
      "metadata": {
        "id": "uLjhZaN02lV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One hot encode data**"
      ],
      "metadata": {
        "id": "VD5GjQqV2_kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars (unique characters in input text):', len(chars))\n",
        "char_indices = dict([(i[-1], i[0]) for i in enumerate(chars)])\n",
        "indices_char = dict([i for i in enumerate(chars)])\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = list()\n",
        "next_chars = list()\n",
        "print('Create sentences and next_chars data...')\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i:i + maxlen:None])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Vectorization...')\n",
        "x = np.zeros([len(sentences), maxlen, len(chars)], dtype=bool)\n",
        "y = np.zeros([len(sentences), len(chars)], dtype=bool)\n",
        "for [i, sentence] in [j for j in enumerate(sentences)]:\n",
        "    for [t, char] in [j for j in enumerate(sentence)]:\n",
        "        x[i][t][char_indices[char]] = 1\n",
        "    y[i][char_indices[next_chars[i]]] = 1\n",
        "print('Done creating one-hot encoded training data.')"
      ],
      "metadata": {
        "id": "oH7XM-gE3D55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build and run the model**"
      ],
      "metadata": {
        "id": "NUA8SEhY4QfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=[maxlen, len(chars)]))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "optimizer = RMSprop(0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.array(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    print()\n",
        "    print('----- Generating text after Epoch:', epoch)\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "        generated = ''\n",
        "        sentence = text[start_index:start_index + maxlen:None]\n",
        "        generated = generated + sentence\n",
        "        print('----- Generating with seed:', sentence)\n",
        "        sys.stdout.write(generated)\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros([1, maxlen, len(chars)])\n",
        "            for [t, char] in [j for j in enumerate(sentence)]:\n",
        "                x_pred[0][t][char_indices[char]] = 1\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            # print('** preds=', preds)\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "            sentence = sentence[1:None:None] + next_char\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "model.fit(x, y, batch_size=128, epochs=30, callbacks=[print_callback])"
      ],
      "metadata": {
        "id": "pQmZ8crr4UDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}